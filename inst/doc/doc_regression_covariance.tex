\documentclass[a4paper,oneside,11pt,DIV=12]{scrartcl}

\usepackage[utf8]{inputenc}
\usepackage{graphicx}

\setkomafont{captionlabel}{\sffamily\bfseries\small}
\setkomafont{caption}{\sffamily\small}

\usepackage[T1]{fontenc}
\usepackage{times}
\renewcommand{\familydefault}{\rmdefault}

\usepackage{amssymb,amsmath,amsthm,mathrsfs}
\usepackage{bbm}
\usepackage{bm}
\usepackage[longnamesfirst]{natbib}
\usepackage{booktabs}
\usepackage{enumerate}

% base font
\usepackage[scaled]{helvet}
\renewcommand*\familydefault{\sfdefault}

% theorems
\theoremstyle{remark}
\newtheorem*{rem}{Remark}
\newtheorem*{rems}{Remarks}

% flush floats using \afterpage{\clearpage}
\usepackage{afterpage}

% allow page breaks of long align equation environments
\allowdisplaybreaks


\usepackage{setspace}
\setlength\parindent{24pt}

\usepackage{hyperref}
\hypersetup{
    colorlinks=true,
    linkcolor=blue,
    filecolor=blue,
    urlcolor=blue,
    citecolor=blue
}

% math
\newcommand{\R}{\mathbb{R}}
\newcommand{\N}{\mathbb{N}}
\newcommand{\E}{\mathbb{E}}
\newcommand{\var}{\mathrm{var}}
\newcommand{\alert}[1]{\textbf{#1}}

% code command (can deal with '$', '_', etc.)
\makeatletter
\newcommand\code{\bgroup\@makeother\_\@makeother\~\@makeother\$\@makeother\^\@codex}
\def\@codex#1{{\normalfont\ttfamily\hyphenchar\font=-1 #1}\egroup}
\makeatother

% ==============================================================================
\begin{document}
\shortcites{anderson_bai_etal_1999}
\shortcites{blackford_petitet_etal_2002}

\title{\Large Model-Based Covariance Estimation for Regression $M$- and
    $GM$-Estimators}

\author{{\normalsize Tobias Schoch} \\
\begin{minipage}[t][][t]{\textwidth}
	\begin{center}
	\small{University of Applied Sciences Northwestern Switzerland FHNW} \\
	\small{School of Business, Riggenbachstrasse 16, CH-4600 Olten} \\
	\small{\texttt{tobias.schoch{@}fhnw.ch}}
	\end{center}
\end{minipage}}

\date{{\small \today}}
\maketitle

\renewenvironment{abstract}{%
\begin{center}\begin{minipage}{0.9\textwidth}
\rule{\textwidth}{0.4pt}
{\sffamily\bfseries\footnotesize Abstract.}\small}
{\par\noindent\rule{\textwidth}{0.4pt}\end{minipage}\end{center}}

%------------------------------------------------------------------------------
\section{Introduction}\label{ch:introduction}
\setstretch{1.1}
The population regression model is given by
\begin{equation*}
    \xi: \quad Y_i = \bm x_i^T \bm{\theta} + \sigma \sqrt{v_i}E_i,
    \qquad \bm{\theta} \in \R^p, \quad \sigma > 0, \quad i \in U,
\end{equation*}
\noindent where the population $U$ is of size $N$; the parameters
$\bm{\theta}$ and $\sigma$ are unknown; the $\bm x_i$'s are known
values (possibly containing outliers), $\bm x_i \in \R^p$, $1 \leq p < N$;
the $v_i$'s are known positive (heteroscedasticity) constants; the errors $E_i$
are independent and identically distributed (i.i.d.) random variables with zero
expectation and unit variance; it is assumed that $\sum_{i \in U} \bm x_i
\bm x_i^T / v_i$ is a non-singular $(p \times p)$ matrix.

It is assumed that a sample $s$ is drawn from $U$ with sampling design $p(s)$
such that the independence structure of model $\xi$ is maintained. The sample
regression $GM$-estimator of $\bm{\theta}$ is defined as the root to
the estimating equation $\widehat{\bm{\Psi}}_n(\bm{\theta},
\sigma) = \bm 0$ (for all $\sigma > 0$), where
\begin{equation*}
    \widehat{\bm{\Psi}}_n(\bm{\theta}, \sigma) = \sum_{i \in s}
    w_i \bm{\Psi}_i(\bm{\theta}, \sigma) \qquad \text{with}
    \qquad \bm{\Psi}_i(\bm{\theta}, \sigma) =
    \eta\left(\frac{y_i - \bm x_i^T \bm{\theta}}{\sigma \sqrt{v_i}},
    \; \bm x_i\right) \frac{\bm x_i}{\sigma \sqrt{v_i}},
\end{equation*}
\noindent where the function $\eta: \R \times \R^p \rightarrow \R$ parametrizes
the following estimators
\begin{align*}
    \eta(r,\bm x) &= \psi(r) && M\text{-estimator},\\
    \eta(r,\bm x) &=\psi(r) \cdot h(\bm x) && \text{Mallows}\;
    GM\text{-estimator},\\
    \eta(r,\bm x) &= \psi\left(\displaystyle{\frac{r}{h(\bm x)}}\right)
    \cdot h(\bm x) && \text{Schweppe}\; GM\text{-estimator},
\end{align*}
\noindent where $\psi:\R \rightarrow \R$ is a continuous, bounded, and odd
(possibly redescending) function, and $h: \R^p \rightarrow \R_+$ is a weight
function.

%------------------------------------------------------------------------------
\section{Covariance estimation}
The model-based covariance matrix of $\bm{\theta}$ is \citep[][Chapter
6.3]{hampel_ronchetti_etal_1986}
\begin{equation}\label{eq:cov}
    \mathrm{cov}_{\xi}(\bm{\theta}, \sigma) = \bm M^{-1}(\bm{\theta}, \sigma)
    \cdot \bm Q(\bm{\theta}, \sigma) \cdot \bm M^{-T}(\bm{\theta}, \sigma)
    \qquad \text{for known} \; \sigma > 0,
\end{equation}
\noindent where
\begin{equation*}
    \bm M(\bm{\theta}, \sigma) = \sum_{i=1}^N \mathrm{E}_{\xi} \big\{
        \bm{\Psi}_i'(\bm{\theta}, \sigma) \big\}, \quad \text{where} \quad
    \bm{\Psi}_i'(\bm{\theta}, \sigma) = -\frac{\partial}{\partial
    \bm{\theta}^*} \bm{\Psi}_i(Y_i, \bm x_i; \bm{\theta}^*, \sigma)
    \bigg\vert_{\bm{\theta}^* = \bm{\theta}},
\end{equation*}
\noindent and
\begin{equation*}
    \bm Q(\bm{\theta}, \sigma) = \frac{1}{N} \sum_{i=1}^N \mathrm{E}_{\xi}
    \big\{ \bm{\Psi}_i(Y_i, \bm x_i; \bm{\theta}, \sigma) \bm{\Psi}_i(Y_i, \bm
    x_i;\bm{\theta}, \sigma)^T \big\},
\end{equation*}
and $\mathrm{E}_{\xi}$ denotes expectation with respect to model $\xi$. For the
sample regression $GM$-estimator $\widehat{\bm{\theta}}_n$, the matrices $\bm
M$ and $\bm Q$ must be estimated. Expressions of the generic matrices $\bm M$
and $\bm Q$ in ($\ref{eq:cov}$) are given as foolows.
\begin{align*}
    \widehat{\bm M}_M &= - \overline{\psi'} \cdot \bm X^T \bm W \bm X &
    \widehat{\bm Q}_M = \overline{\psi^2} \cdot \bm X^T \bm W \bm X &&
    M\text{-est.}\\
    %
    \widehat{\bm M}_{Mal} &= - \overline{\psi'} \cdot \bm X^T \bm W \bm
    H \bm X & \widehat{\bm Q}_{Mal} = \overline{\psi^2} \cdot \bm X^T
    \bm W \bm H^2 \bm X && GM\text{-est. (Mallows)}\\
    %
    \widehat{\bm M}_{Sch} &= - \bm X^T \bm W \bm S_1 \bm X &
    \widehat{\bm Q}_{Sch} = \bm X^T \bm W \bm S_2 \bm X &&
    GM\text{-est. (Schweppe)}
\end{align*}
\noindent where
\begin{align*}
    \bm W &= \mathrm{diag}_{i=1,\ldots,n}\{w_i\},
    & \bm H &= \mathrm{diag}_{i=1,\ldots,n}\{h(\bm x_i)\},\\
    %
    \overline{\psi'} &= \frac{1}{\widehat{N}}\sum_{i \in s} w_i \psi' \left(
    \frac{r_i}{\widehat{\sigma} \sqrt{v_i}} \right),
    & \overline{\psi^2} &= \frac{1}{\widehat{N}}\sum_{i \in s} w_i \psi^2 \left(
    \frac{r_i}{\widehat{\sigma} \sqrt{v_i}} \right),\\
    %
    \bm S_1 &= \mathrm{diag}_{i=1,\ldots,n} \big\{ s_1^i \big\}, 
    & s_1^i &= \frac{1}{\widehat{N}}\sum_{j \in s} w_j
    \psi'\left(\frac{r_j}{h(\bm x_i)\widehat{\sigma} \sqrt{v_j}}\right),
\end{align*}
\noindent and
\begin{align*}
    \bm S_2 &= \mathrm{diag}_{i=1,\ldots,n} \big\{ s_2^i \big\},
    & s_2^i &= \frac{1}{\widehat{N}}\sum_{j \in s} w_j
    \psi^2\left(\frac{r_j}{h(\bm x_i)\widehat{\sigma} \sqrt{v_j}}\right).
\end{align*}

\begin{rems}~
    \begin{itemize}
        \item The $i$-th diagonal element of $\bm S_1$ and $\bm S_2$ depends on
            $h(\bm x_i)$, but the summation is over $j \in s$; see also
            \citep[][Chapter 6]{marazzi_1987}.
        \item When $\bm W$ is equal to the identity matrix $\bm I$, the
            asymptotic covariance of $\widehat{\bm{\theta}}_M$ is equal to the
            expression in \citet[][Eq. 6.5]{huber_1981}, which is implemented
            in the R packages \code{MASS} \citep{venables_ripley_2002} and
            \code{robeth} \citep{marazzi_2020}.
        \item For the Mallows and Schweppe type $GM$-estimators and given that
            $\bm W = \bm I$, the asymptotic covariance coincides with the one
            implemented in package/ library \code{robeth} for the option
            ``averaged''; see \citet[][Chapter 4]{marazzi_1993} and
            \citet[][Chapter 2.6]{marazzi_1987} on the earlier \code{ROBETH-85}
            implementation.
    \end{itemize}
\end{rems}
%------------------------------------------------------------------------------
\section{Implementation}
The main function -- which is only a wrapper function -- is
\code{cov_reg_model}. The following display shows  pseudo code of the main
function.

\begin{verbatim}
cov_reg_model()
{
    get_psi_function()          // get psi function (fun ptr)
    get_psi_prime_function()    // get psi-prime function (fun ptr)
    switch(type) {
        case 0: cov_m_est()             // M-estimator
        case 1: cov_mallows_gm_est()    // Mallows GM-estimator
        case 2: cov_schweppe_gm_est()   // Schweppe GM-estimator
    }
    robsurvey_error()           // signal error in case of failure
}
\end{verbatim}

\noindent The functions \code{cov_m_est()}, \code{cov_mallows_gm_est()}, and
\code{cov_schweppe_gm_est()} implement the covariance estimators; see below.
All functions are based on the subroutines in \code{BLAS}
\citep{blackford_petitet_etal_2002} and \code{LAPACK}
\citep{anderson_bai_etal_1999}.

To fix notation, denote the Hadamard product of the matrices $\bm A$ and $\bm
B$ by $\bm A\circ \bm B$ and suppose that $\sqrt{\cdot}$ is applied element by
element.

%---------------------------------------
\subsection{$M$-estimator}
The covariance matrix is (up to $\widehat{\sigma}$) equal to (see
\code{cov_m_est})
\begin{equation}\label{eq:cov_m}
   (\bm X^T \bm W \bm X)^{-1}
\end{equation}
\noindent and is computed as follows:
\begin{itemize}
    \item Compute the factorization $\sqrt{\bm w} \circ \bm X := \bm Q \bm R$
        (LAPACK: \code{dgeqrf}).
    \item Invert the upper triangular matrix $\bm R$ by backward substitution
        to get $\bm R^{-1}$ (LAPACK: \code{dtrtri}).
    \item Compute $\bm R^{-1} \bm R^{-T}$, which is equal to
        ($\ref{eq:cov_m}$); taking advantage of the triangular shape of $\bm
        R^{-1}$ and $\bm R^{-T}$ (LAPACK: \code{dtrmm}).
\end{itemize}

%---------------------------------------
\subsection{Mallows $GM$-estimator}
The covariance matrix is (up to $\widehat{\sigma}$) equal to (see
\code{cov_mallows_gm_est})
\begin{equation}\label{eq:cov_mallows}
   \big(\bm X^T \bm W \bm H \bm X\big)^{-1} \bm X^T \bm W \bm H^2 \bm X
    \big(\bm X^T \bm W \bm H \bm X\big)^{-1}
\end{equation}
\noindent and is computed as follows:

\begin{itemize}
    \item Compute the QR factorization: $\sqrt{\bm w \cdot \bm h} \circ \bm X
        := \bm Q \bm R$ (LAPACK: \code{dgeqrf}).
    \item Invert the upper triangular matrix $\bm R$ by backward substitution
        to get $\bm R^{-1}$ (LAPACK: \code{dtrtri}).
    \item Define a new matrix: $\bm A \leftarrow \sqrt{\bm h} \circ \bm Q$
        (extraction of $\bm Q$ matrix with LAPACK: \code{dorgqr}).
    \item Update the matrix: $\bm A \leftarrow \bm A \bm R^{-T}$ (taking
        advantage of the triangular shape of $\bm R^{-1}$; LAPACK:
        \code{dtrmm}).
    \item Compute $\bm A \bm A^T$, which corresponds to the expression in
        ($\ref{eq:cov_mallows}$); (LAPACK: \code{dgemm}).
\end{itemize}

%---------------------------------------
\subsection{Schweppe $GM$-estimator}
The covariance matrix is (up to $\widehat{\sigma}$) equal to (see
\code{cov_schweppe_gm_est})
\begin{equation}\label{eq:cov_schweppe}
   \big(\bm X^T \bm W \bm S_1 \bm X\big)^{-1} \bm X^T \bm W \bm S_2 \bm X
    \big(\bm X^T \bm W \bm S_1 \bm X\big)^{-1}.
\end{equation}
\noindent Put $\bm s_1 = \mathrm{diag}(\bm S_1)$, $\bm s_2 = \mathrm{diag}(\bm
S_2)$, and let $\cdot / \cdot $ denote elemental division (i.e., the inverse of
the Hadamard product). The covariance matrix in ($\ref{eq:cov_schweppe}$) is
computed as follows

\begin{itemize}
    \item Compute the factorization $\sqrt{\bm w \circ \bm s_1} \circ \bm X :=
        \bm Q \bm R$ (LAPACK: \code{dgeqrf}).
    \item Invert the upper triangular matrix $\bm R$ by backward substitution
        to get $\bm R^{-1}$ (LAPACK: \code{dtrtri}).
    \item Define a new matrix: $\bm A \leftarrow \sqrt{\bm s_2 / \bm s_1 }
        \circ \bm Q$ (extraction of $\bm Q$ matrix with LAPACK: \code{dorgqr}).
    \item Update the matrix: $\bm A \leftarrow \bm A \bm R^{-T}$ (taking
        advantage of the triangular shape of $\bm R^{-1}$; LAPACK:
        \code{dtrmm}).
    \item Compute $\bm A \bm A^T$, which corresponds to the expression in
        ($\ref{eq:cov_schweppe}$); (LAPACK: \code{dgemm}).
\end{itemize}

\begin{rem}
\citet{marazzi_1987} uses the Cholesky factorization (see his subroutines
\code{RTASKV} and \code{RTASKW}) which is computationally a bit cheaper
than our QR factorization.
\end{rem}

%------------------------------------------------------------------------------
\clearpage
\bibliographystyle{fhnw_en}
\bibliography{master}

\end{document}
