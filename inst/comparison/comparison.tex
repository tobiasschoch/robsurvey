\documentclass[a4paper]{scrartcl}
\setlength{\textheight}{1.1\textheight}
\usepackage[T1]{fontenc}
\usepackage[utf8]{inputenc}

\usepackage{amsfonts}
\usepackage{amsmath}
\usepackage{amssymb}

\usepackage{framed}

\usepackage{Sweave}

\usepackage{setspace}

\begin{document}

\title{Comparison of the methods \texttt{svyreg\_huber} and \texttt{svyreg\_huberGM} in package \texttt{robsurvey} with other implementations of regression $M$- and $GM$-estimators\footnote{Version 0.2 of \texttt{robsurvey}.}} 

\author{Beat Hulliger and Tobias Schoch\footnote{Corresponding author; e-mail: tobias.schoch \texttt{[at]} fhnw.ch.}\\
  \multicolumn{1}{p{.7\textwidth}}{\centering\emph{\small University of Applied Sciences Northwestern Switzerland, School of Business, Riggenbachstrasse 16, CH-4600 Olten, Switzerland}}}

\date{\small\today}
\maketitle

\setstretch{1.15}


%-------------------------------------------------------------------------------
\section{Introduction}\label{sec:intro}
In this short report, we compare the behavior of the regression $M$- and $GM$-estimators in package \texttt{robsurvey} with the methods from other implementations. To this end, we study the estimated parameters for 4 well-known datasets/ cases studies. With regard to competing implementations, we consider the methods from the following \texttt{R} packages: 
\begin{Schunk}
\begin{Soutput}
MASS, version: 7.3.51.1
robeth, version: 2.7.6
robustbase, version: 0.93.4
\end{Soutput}
\end{Schunk}
\noindent These packages are documented in, respectively, \cite{mass}, \cite{robeth}, and \cite{robustbase}. 

The estimators in \texttt{robsurvey} stand out from the methods in the above listed packages in that they explicitly compute weighted estimates of finite population quantities.   

In all comparisons, we 
\begin{itemize}
   \item study $M$- or $GM$-estimators with the MAD (normalized median absolute deviation) as estimator of scale;
   \item use the robustness tuning constant \texttt{k = 1.345} of the Huber $\psi$-function;
   \item focus on sample data that do not contain sampling weights. 
\end{itemize}
\noindent All studied methods compute the regression estimates by iteratively reweighted least squares (IRWLS) and the estimate of scale (more precisely, the trial value for the scale estimate) is updated at each iteration. 

\begin{leftbar}
\textbf{Limitations:} Our comparisons provide only anecdotal evidence on the performance of the methods. An in-depth simulation study would be necessary to conclude that our implementations behave properly. Nonetheless, we believe that the comparisons shed some light on the behavior of our implementations. 
\end{leftbar}

The remainder of the paper is organized as follows. In Section \ref{sec:mest}, we compare several implementations of the Huber $M$-estimator of regression. Section \ref{sec:gmest} studies  implementations of the Huber $GM$-estimator of regression. In Section \ref{sec:summary}, we summarize the findings. 

%-------------------------------------------------------------------------------
\section{Huber $M$-estimators of regression}\label{sec:mest}
In this section, we study the Huber $M$-estimator of regression. The parametrizations of the algorithms have been chosen to make them comparable; we use: 
\begin{itemize}
   \item \texttt{MASS::rlm}: \texttt{method = "M"}, \texttt{scale.est = "MAD"}, \texttt{acc = 1e-5}, \texttt{test.vec = "coef"}
   \item \texttt{robeth::rywalg}: \texttt{tol = 0.0001}, \texttt{itype = 1}, \texttt{isigma = 2}, \texttt{icnv = 1}, \texttt{maxis = 1}; see \cite{marazzi1993} for more details.	
   \item \texttt{robsurvey::svyreg\_huber}: \texttt{acc = 1e-5}, 
\end{itemize}

\subsection{Case 1: \texttt{education} data}\label{sec:education}
The \texttt{education} data are on public education expenditures (at the level of US states), and are from \cite{chatterjeeprice} (see \cite{chatterjeehadi} for a newer edition); see also \cite{rousseeuwleroy}. The data set contains four variables: the response variable (\texttt{Y}: per capita expenditure on public education in a state, projected for 1975) and the three explanatory variables
\begin{itemize}
   \item \texttt{X1}: Number of residents per thousand residing in urban areas in 1970,
   \item \texttt{X2}: Per capita personal income in 1973,
   \item \texttt{X3}: Number of residents per thousand under 18 years of age in 1974.
\end{itemize}

\noindent There are 50 observations on the four variables. The first 6 rows are shown below. 
\begin{Schunk}
\begin{Sinput}
> data(education, package = "robustbase")
> head(education)
\end{Sinput}
\begin{Soutput}
  State Region  X1   X2  X3   Y
1    ME      1 508 3944 325 235
2    NH      1 564 4578 323 231
3    VT      1 322 4011 328 270
4    MA      1 846 5233 305 261
5    RI      1 871 4780 303 300
6    CT      1 774 5889 307 317
\end{Soutput}
\end{Schunk}

\noindent The following tabular output shows the estimated coefficients (and the estimated scale; last column) under the model \texttt{Y $\sim$ X1 + X2 + X3} for four different implementations/ methods. 
\begin{Schunk}
\begin{Soutput}
                    (Intercept)     X1     X2     X3   scale
svyreg_huber          -434.8370 0.0304 0.0607 1.2697 40.3786
rywalg (ROBETH)       -434.4675 0.0307 0.0606 1.2690 40.1614
rlm (MASS)            -434.3948 0.0307 0.0606 1.2689 40.1200
rlm2 (modified rlm)   -434.8375 0.0304 0.0607 1.2697 40.3786
\end{Soutput}
\end{Schunk}

\noindent The estimates of the four methods differ only slightly. The main reason for the differences can be traced back to the type of scale estimator that is used. Method \texttt{svyreg\_huber} uses the (normalized, weighted) median of the absolute deviations of the residuals from the (weighted) median of the residuals, whereas the methods \texttt{rywalg} and \texttt{rlm} use the (normalized) median of the absolute residuals. To substantiate this claim, we also studied a slight modification of method \texttt{rlm} (see \texttt{rlm2}). The method \texttt{rlm2} is identical to \texttt{rlm}, except that the scale is estimated by the MAD, \texttt{stats::mad(x = resid, center = median(x))}, instead of \texttt{median(abs(resid))/0.6745}, where \texttt{resid} denotes the residuals. We observe from the above tabulated data that the results of \texttt{svyreg\_huber} and \texttt{rlm2} are virtually identical.


%-------------------------------------------------------------------------------
\subsection{Case 2: \texttt{stackloss} data}
The \texttt{stackloss} data consist of 21 measurements on the oxidation of ammonia to nitric acid for an industrial process; see \cite{brownlee}. The variables are: 
\begin{itemize}
   \item \texttt{Air Flow}: flow of cooling air,
   \item \texttt{Water Temp}: cooling water inlet temperature,
   \item \texttt{Acid Conc.}: concentration of acid [per 1000, minus 500],
   \item \texttt{stack.loss}: stack loss.
\end{itemize}

\noindent The first 6 observations are shown below.

\begin{Schunk}
\begin{Sinput}
> data(stackloss, package = "datasets")
> head(stackloss)
\end{Sinput}
\begin{Soutput}
  Air.Flow Water.Temp Acid.Conc. stack.loss
1       80         27         89         42
2       80         27         88         37
3       75         25         90         37
4       62         24         87         28
5       62         22         87         18
6       62         23         87         18
\end{Soutput}
\end{Schunk}

\noindent The variable \texttt{stack.loss} (stack loss of amonia) is regressed on the explanatory variables air flow, water temperature and the concentration of acid. The regression coefficients and the estimate of scale are tabulated for the four implementations/ methods under study. 

\begin{Schunk}
\begin{Soutput}
                    (Intercept) Air.Flow Water.Temp Acid.Conc.  scale
svyreg_huber           -41.0512   0.8267     0.9385    -0.1286 2.5300
rywalg (ROBETH)        -41.0269   0.8293     0.9263    -0.1279 2.4419
rlm (MASS)             -41.0265   0.8294     0.9261    -0.1278 2.4407
rlm2 (modified rlm)    -41.0511   0.8267     0.9385    -0.1286 2.5299
\end{Soutput}
\end{Schunk}

\noindent The estimates of the four methods differ only slightly. The discrepancies can be explained (for the most part) by the choice of MAD that is used to compute the regression scale; viz. Section \ref{sec:education}. 


%-------------------------------------------------------------------------------
\section{Huber $GM$-estimators of regression}\label{sec:gmest}
In this section, we consider regression $GM$-estimators with Huber $\psi$-function (tuning constant fixed at $k=1.345$). The scale is estimated by MAD. With regard to the MAD, we distinguish two cases: 
\begin{itemize}
   \item \texttt{MAD0}: (normalized) MAD about zero, i.e., \texttt{mad(x, center = 0)},
   \item \texttt{MAD}: (normalized) MAD about the median, i.e. \texttt{mad(x, center = median(x))}.
\end{itemize}

\noindent For the purpose of comparison, we introduce the function \texttt{GM} (see Appendix). This function computes Mallows and Schweppe type regression $GM$-estimators (only Huber $\psi$-function). For instance, the label \texttt{GM (Mallows, MAD0)} refers to the Mallows type $GM$-estimator with scale estimated by \texttt{MAD0}. 

We computed the weights to downweight leverage observations (\texttt{xwgt}) with the help of the methods in package \texttt{robeth}. The so computed weights were then stored to be utilized in all implementations of $GM$-estimators of regression. This approach ensures that the implementations do not differ in terms of the \texttt{xgwt}'s. 

%-------------------------------------------------------------------------------
\subsection{Case 3: \texttt{delivery} data}
The \texttt{delivery} data consist of observations on servicing 25 soft drink vending machines. The data are from \cite{montgomerypeck}; see also \cite{rousseeuwleroy}. The variables are:

\begin{itemize}
   \item \texttt{n.prod}: number of products stocked in the vending machine,
   \item \texttt{distance}: distance walked by the route driver (ft), 
   \item \texttt{delTime}: delivery time (minutes).
\end{itemize}

\noindent The goal is to model/ predict the amount of time required by the route driver to service the vending machines. The first six observations are shown below.

\begin{Schunk}
\begin{Sinput}
> data(delivery, package = "robustbase")
> head(delivery)
\end{Sinput}
\begin{Soutput}
  n.prod distance delTime
1      7      560   16.68
2      3      220   11.50
3      3      340   12.03
4      4       80   14.88
5      6      150   13.75
6      7      330   18.11
\end{Soutput}
\end{Schunk}

\noindent The variable \texttt{delTime} is regressed on the variables \texttt{n.prod} and \texttt{distance}.


\subsubsection{Mallows $GM$-estimator}\label{sec:delivery_mallows}
\noindent The regression coefficients and the estimate of scale are tabulated for the four implementations/ methods under study.
 
\begin{Schunk}
\begin{Soutput}
                         (Intercept) n.prod distance scale
rywalg (ROBETH, Mallows)       4.476  1.509     0.01 2.255
GM (Mallows, MADzero)          4.476  1.509     0.01 2.255
GM (Mallows, MAD)              4.468  1.514     0.01 2.446
svyreg_huberGM (Mallows)       4.468  1.514     0.01 2.446
\end{Soutput}
\end{Schunk}

\noindent In view of the tabulated results, we formulate the following two equivalence statements: 
\begin{align*}
   \mathtt{rywalg \;(ROBETH, \;Mallows)} &\equiv \mathtt{GM \;(Mallows, \;MADzero)} \\
   %
   \mathtt{GM \;(Mallows, \;MAD)} &\equiv \mathtt{svyreg\_huberGM \;(Mallows)} 
\end{align*}
\noindent Since the implementations \texttt{GM (Mallows, MADzero)} and \texttt{GM (Mallows, MAD)} differ only in terms of the MAD, we argue that the results of \texttt{svyreg\_huberGM (Mallows)} are comparable to the ones of \texttt{rywalg (ROBETH, Mallows)}.

\subsubsection{Schweppe $GM$-estimator}\label{sec:delivery_schweppe}
In view of the tabulated results (see below), we can formulate the following equivalence relation  
\begin{equation*}
   \mathtt{GM \;(Schweppe, \;MAD)} \equiv \mathtt{svyreg\_huberGM \;(Schweppe)}. 
\end{equation*}
\noindent The second equivalence relation that we established in the last paragraph for the Mallows type estimator does not hold here; see \texttt{rywalg (ROBETH, Schweppe)} differs from \texttt{GM (Schweppe, MADzero)}. We do not know the cause. Fortunately, the discrepancies are not great. 

\begin{Schunk}
\begin{Soutput}
                          (Intercept) n.prod distance scale
rywalg (ROBETH, Schweppe)       3.964  1.430    0.014 1.434
GM (Schweppe, MADzero)          4.012  1.429    0.014 1.392
GM (Schweppe, MAD)              4.011  1.429    0.014 1.398
svyreg_huberGM (Schweppe)       4.011  1.429    0.014 1.398
\end{Soutput}
\end{Schunk}


%-------------------------------------------------------------------------------
\subsection{Case 4: \texttt{salinity} data}
The \texttt{salinity} data are a set of measurements of water salinity and river discharge taken in North Carolina's Pamlico Sound; \cite{ruppertcarroll}; see also \cite{rousseeuwleroy}. The variables are

\begin{itemize}
   \item \texttt{Y}: salinity, 
   \item \texttt{X1}: salinity lagged two weeks,
   \item \texttt{X2}: linear time trend, 
   \item \texttt{X3}: river discharge.
\end{itemize}

\noindent There a 28 observations. The first six observations are shown below.

\begin{Schunk}
\begin{Sinput}
> data(salinity, package = "robustbase")
> head(salinity)
\end{Sinput}
\begin{Soutput}
   X1 X2     X3   Y
1 8.2  4 23.005 7.6
2 7.6  5 23.873 7.7
3 4.6  0 26.417 4.3
4 4.3  1 24.868 5.9
5 5.9  2 29.895 5.0
6 5.0  3 24.200 6.5
\end{Soutput}
\end{Schunk}

\noindent We consider fitting the model \texttt{Y $\sim$ X1 + X2 + X3} by several implementations of the regression $GM$-estimators. 



\subsubsection{Mallows $GM$-estimator}
The findings (see tabulated results, below) are analogous to the results discussed in Section \ref{sec:delivery_mallows}. We therefore conclude that the implementation \texttt{svyreg\_huberGM} for the Mallows $GM$-estimator is comparable to the other implementations.

\begin{Schunk}
\begin{Soutput}
                         (Intercept)    X1     X2     X3 scale
rywalg (ROBETH, Mallows)      18.868 0.721 -0.174 -0.654 0.774
GM (Mallows, MADzero)         18.869 0.721 -0.174 -0.654 0.774
GM (Mallows, MAD)             18.884 0.721 -0.174 -0.655 0.763
svyreg_huberGM (Mallows)      18.884 0.721 -0.174 -0.655 0.763
\end{Soutput}
\end{Schunk}

\subsubsection{Schweppe $GM$-estimator}
The application of Schweppe type $GM$-estimator to the \texttt{salinity} data confirms the findings that we have encountered in our discussion of the  \texttt{delivery} data; see Section \ref{sec:delivery_schweppe}. Notably, with our estimator \texttt{GM (Mallows, MAD)} we cannot replicate the results of \texttt{rywalg (ROBETH, Schweppe)}. Fortunately, the results of the two implementations differ only slightly and are thus no cause for severe concerns. 


\begin{Schunk}
\begin{Soutput}
                          (Intercept)    X1     X2     X3 scale
rywalg (ROBETH, Schweppe)      19.974 0.680 -0.177 -0.679 0.732
GM (Schweppe, MADzero)         19.902 0.679 -0.173 -0.675 0.754
GM (Schweppe, MAD)             19.911 0.679 -0.173 -0.675 0.707
svyreg_huberGM (Schweppe)      19.911 0.679 -0.173 -0.675 0.707
\end{Soutput}
\end{Schunk}


%-------------------------------------------------------------------------------
\section{Summary and conclusions}\label{sec:summary}
In this paper, we studied the behavior of the methods \texttt{svyreg\_huber}  and \texttt{svyreg\_huberGM} in package \texttt{robsurvey} with other implementations. We restricted attention to studying the methods for four well-known datasets. For all datasets under study, our implementations replicate (or are at least very close to) the results of the competing implementations. Although our comparisons provide only anecdotal evidence on the performance of the methods, we believe that the comparisons shed some light on the behavior of our implementations. We are fairly confident that the methods \texttt{svyreg\_huber}  and \texttt{svyreg\_huberGM} behave the way they are supposed to. 


%-------------------------------------------------------------------------------
\begin{thebibliography}{9}

\bibitem{brownlee}
Brownlee, K. A. (1965). Statistical Theory and Methodology in Science and 
   Engineering, 2nd ed., John Wiley and Sons, New York.

\bibitem{chatterjeeprice} 
Chatterjee, S. and B. Price (1977). Regression Analysis by Example, John Wiley
   and Sons, New York. 

\bibitem{chatterjeehadi} 
Chatterjee, S. and A. S. Hadi (2012). Regression Analysis by Example, 5th ed., 
   John Wiley and Sons, Hoboken (NJ). 

\bibitem{robustbase} 
M{\"a}chler, M., P. Rousseeuw, C. Croux, V. Todorov, A. Ruckstuhl, M. 
   Salibian-Barrera, T. Verbeke, M. Koller, E. L. T. Conceicao, and 
   M. A. di Palma (2019). robustbase: Basic 
   Robust Statistics R package version 0.93-4. 
   URL http://CRAN.R-project.org/package=robustbase

\bibitem{robeth} 
Marazzi, A. (2020). robeth: R Functions for Robust Statistics. 
   R package version 2.7-6. 
   URL https://CRAN.R-project.org/package=robeth

\bibitem{marazzi1993}
Marazzi, A. (1993). Algorithms, Routines, and S-Functions for Robust Statistics: 
   The Fortran Library ROBETH with an interface to S-PLUS, 
   Chapman and Hall/ CRC, New York. (with the collab. of Johann Joss, Alex 
   Randriamiharisoan)

\bibitem{montgomerypeck}
Montgomery, D. C. and E. A. Peck (2006). Introduction to Linear Regression
   Analysis, 4th ed., John Wiley and Sons, Hoboken (NJ).

\bibitem{rousseeuwleroy}
Rousseeuw, P. J. and A. M. Leroy (1987). Robust Regression and Outlier 
   Detection, John Wiley and Sons, Hoboken (NJ). 

\bibitem{ruppertcarroll}
Ruppert, D. and R. J. Carroll (1980). Trimmed Least Squares Estimation in the 
   Linear Model. Journal of the American Statistical Association 75 (372), 
   pp. 828--838.

\bibitem{mass} 
Venables, W. N. and B.D. Ripley (2002). Modern Applied Statistics with S, 
   4th ed., Springer, New York. 
\end{thebibliography}

%-------------------------------------------------------------------------------
\appendix

\section{Listing of the function \texttt{GM}}
The following function is used as a reference. It computes Mallows and Schweppe type regression $GM$-estimates (with Huber $\psi$-function and the tuning constant fixed at $k=1.345$). The function is in no way ``waterproof'' and should not be used in practice. 

\setstretch{1}

\begin{Schunk}
\begin{Soutput}
function(formula, data, xwgt, zero = FALSE, Mallows = TRUE, tol = 1e-5, 
   low = FALSE, high = FALSE) 
{
   mf <- model.frame(formula, data)
   y <- as.numeric(model.response(mf))
   x <- model.matrix(terms(formula), mf)  

   tmp <- lm.fit(x, y)
   beta0 <- tmp$coefficients 
   resid <- tmp$resid 
   scale0 <- mad(resid)   
 
   if (Mallows) { # determine consistency correction for Mallows type estimator
      foo <- function(x, wgt) sum(pnorm(x, 0, sqrt(wgt))) / length(wgt) - 0.75 
      const <- uniroot(foo, c(0.1, 5), xwgt)$root
   } else
      const <- 0.6744898

   while (1) {
      tmp <- if (Mallows)
	    lm.wfit(x, y, xwgt * huberWgt(resid / scale0))
	 else
	    lm.wfit(x, y, huberWgt(resid / (xwgt * scale0)))
      
      beta <- tmp$coefficients 
      resid <- tmp$residuals

      r <- if (Mallows) 
	 resid * sqrt(xwgt)
      else 
	 resid

      scale <- if (zero)
	 mad(r, center = 0, constant = 1 / const, high = TRUE)
      else
	 mad(r, constant = 1 / const)

      if (norm(as.matrix(beta - beta0)) < tol * scale) 
	 break
      else {
	 beta0 <- beta; scale0 <- scale
      }
   }
   list(coef = beta, scale = scale)
}
<bytecode: 0x000000001eeba648>
\end{Soutput}
\end{Schunk}

\setstretch{1.15}

\section{R session information}
\begin{itemize}\raggedright
  \item R version 3.5.3 (2019-03-11), \verb|x86_64-w64-mingw32|
  \item Running under: \verb|Windows 10 x64 (build 18363)|
  \item Matrix products: default
  \item Base packages: base, datasets, graphics, grDevices, grid,
    methods, stats, utils
  \item Other packages: MASS~7.3-51.1, Matrix~1.2-15, robeth~2.7-6,
    robsurvey~0.2, robustbase~0.93-4, survey~3.35-1, survival~2.43-3
  \item Loaded via a namespace (and not attached): compiler~3.5.3,
    DEoptimR~1.0-8, lattice~0.20-38, splines~3.5.3, tools~3.5.3
\end{itemize}
\end{document} 
